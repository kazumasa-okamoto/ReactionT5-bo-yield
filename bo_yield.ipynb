{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "399f6a19",
   "metadata": {},
   "source": [
    "## データセットの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "474abd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad075c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def space_clean(row):\n",
    "    row = row.replace(\". \", \"\").replace(\" .\", \"\").replace(\"  \", \" \")\n",
    "    return row\n",
    "\n",
    "\n",
    "def canonicalize(smiles):\n",
    "    try:\n",
    "        new_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles), canonical=True)\n",
    "    except:\n",
    "        new_smiles = None\n",
    "    return new_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b6b1767",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/inchi_23l_reaction_t5_ready.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8190d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必須カラムの存在チェックと補完\n",
    "required_cols = [\"REACTANT\", \"CATALYST\", \"REAGENT\", \"SOLVENT\", \"PRODUCT\"]\n",
    "for col in required_cols:\n",
    "    if col not in df.columns:\n",
    "        df[col] = \"\"\n",
    "\n",
    "# 必要に応じてYIELDを標準化（0-1に正規化）\n",
    "if \"YIELD\" in df.columns and df[\"YIELD\"].max() >= 100:\n",
    "    df[\"YIELD\"] = df[\"YIELD\"].clip(0, 100) / 100\n",
    "else:\n",
    "    df[\"YIELD\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "786c0f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"REAGENT\", \"REACTANT\", \"PRODUCT\"]:\n",
    "    df[col] = df[col].apply(space_clean)\n",
    "    df[col] = df[col].apply(lambda x: canonicalize(x) if x != \" \" else \" \")\n",
    "    df = df[~df[col].isna()].reset_index(drop=True)\n",
    "    df[col] = df[col].apply(lambda x: \".\".join(sorted(x.split(\".\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "130c5fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"REAGENT\"] = df[\"CATALYST\"].fillna(\" \") + \".\" + df[\"REAGENT\"].fillna(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a03ecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df[[\"YIELD\"]].drop_duplicates().index].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74faba6",
   "metadata": {},
   "source": [
    "## モデルの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b32b72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/ReactionT5-bo-yield/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, T5ForConditionalGeneration, AutoConfig, PreTrainedModel\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a161557",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReactionT5Yield(PreTrainedModel):\n",
    "    config_class  = AutoConfig\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(self.config._name_or_path)\n",
    "        self.model.resize_token_embeddings(self.config.vocab_size)\n",
    "        self.fc1 = nn.Linear(self.config.hidden_size, self.config.hidden_size//2)\n",
    "        self.fc2 = nn.Linear(self.config.hidden_size, self.config.hidden_size//2)\n",
    "        self.fc3 = nn.Linear(self.config.hidden_size//2*2, self.config.hidden_size)\n",
    "        self.fc4 = nn.Linear(self.config.hidden_size, self.config.hidden_size)\n",
    "        self.fc5 = nn.Linear(self.config.hidden_size, 1)\n",
    "\n",
    "        self._init_weights(self.fc1)\n",
    "        self._init_weights(self.fc2)\n",
    "        self._init_weights(self.fc3)\n",
    "        self._init_weights(self.fc4)\n",
    "        self._init_weights(self.fc5)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.01)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.01)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        device = inputs['input_ids'].device\n",
    "\n",
    "        with torch.no_grad():\n",
    "            encoder_outputs = self.model.encoder(\n",
    "                input_ids=inputs['input_ids'],\n",
    "                attention_mask=inputs.get('attention_mask', None),\n",
    "            )\n",
    "            encoder_hidden_states = encoder_outputs[0]  # (B, L, H)\n",
    "\n",
    "            dec_input_ids = torch.full(\n",
    "                (inputs['input_ids'].size(0), 1),\n",
    "                self.config.decoder_start_token_id,\n",
    "                dtype=torch.long,\n",
    "                device=device,\n",
    "            )\n",
    "\n",
    "            outputs = self.model.decoder(\n",
    "                input_ids=dec_input_ids,\n",
    "                encoder_hidden_states=encoder_hidden_states,\n",
    "            )\n",
    "            last_hidden_states = outputs[0]  # (B, 1, H)\n",
    "\n",
    "        output1 = self.fc1(last_hidden_states.view(-1, self.config.hidden_size))\n",
    "        output2 = self.fc2(encoder_hidden_states[:, 0, :].view(-1, self.config.hidden_size))\n",
    "        output = self.fc3(torch.hstack((output1, output2)))\n",
    "        output = self.fc4(output)\n",
    "        output = self.fc5(output)\n",
    "        return output * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f496cef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 収率予測（スカラー出力）\n",
    "yield_tokenizer = AutoTokenizer.from_pretrained(\"sagawa/ReactionT5v2-yield\")\n",
    "yield_model = ReactionT5Yield.from_pretrained(\"sagawa/ReactionT5v2-yield\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82f5b903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropoutレイヤーを学習モードに設定する関数\n",
    "def enable_dropout(model):\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.Dropout):\n",
    "            module.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0742088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MC Dropoutによる推論\n",
    "def mc_dropout_inference(model, tokenizer, reaction_smiles, n_samples=100, max_length=512):\n",
    "    model.eval()  # まずモデル全体を評価モードに\n",
    "    enable_dropout(model)  # Dropoutレイヤーのみ学習モードに\n",
    "    \n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    # 単一の文字列の場合リストに変換\n",
    "    if isinstance(reaction_smiles, str):\n",
    "        reaction_smiles = [reaction_smiles]\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_samples):\n",
    "            batch_predictions = []\n",
    "            \n",
    "            for smiles in reaction_smiles:\n",
    "                # トークン化\n",
    "                inputs = tokenizer(\n",
    "                    smiles, \n",
    "                    return_tensors=\"pt\", \n",
    "                    max_length=max_length,\n",
    "                    padding=True,\n",
    "                    truncation=True\n",
    "                ).to(device)\n",
    "                \n",
    "                # 予測実行\n",
    "                output = model(inputs)\n",
    "                batch_predictions.append(output.cpu().numpy().flatten())\n",
    "            \n",
    "            predictions.append(np.array(batch_predictions))\n",
    "    \n",
    "    # 結果を配列に変換: (n_samples, n_reactions)\n",
    "    predictions = np.array(predictions)\n",
    "    \n",
    "    # 統計量計算\n",
    "    mean_pred = np.mean(predictions, axis=0)\n",
    "    var_pred = np.var(predictions, axis=0)\n",
    "    \n",
    "    if len(reaction_smiles) == 1:\n",
    "        return {\n",
    "            'mean': float(mean_pred[0]),\n",
    "            'variance': float(var_pred[0])\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            'mean': mean_pred.tolist(),\n",
    "            'variance': var_pred.tolist()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce704e3e",
   "metadata": {},
   "source": [
    "## ベイズ最適化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9zyzrfudbg",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d1uliljyvxh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 辞書作成関数\n",
    "def create_reaction_dictionaries(df):\n",
    "    \"\"\"\n",
    "    データセットから反応辞書を作成\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (reactant_list, reagent_list, product_list, product_dict, true_yield_dict)\n",
    "    \"\"\"\n",
    "    reactant_list = sorted(df[\"REACTANT\"].unique())\n",
    "    reagent_list = sorted(df[\"REAGENT\"].unique())\n",
    "    product_list = sorted(df[\"PRODUCT\"].unique())\n",
    "    \n",
    "    # (reactant, reagent) -> product のマッピング\n",
    "    product_dict = {\n",
    "        (row[\"REACTANT\"], row[\"REAGENT\"]): row[\"PRODUCT\"]\n",
    "        for _, row in df.iterrows()\n",
    "    }\n",
    "    \n",
    "    # (reactant, reagent, product) -> yield のマッピング\n",
    "    true_yield_dict = {\n",
    "        (row[\"REACTANT\"], row[\"REAGENT\"], row[\"PRODUCT\"]): row[\"YIELD\"]\n",
    "        for _, row in df.iterrows()\n",
    "    }\n",
    "    \n",
    "    print(f\"Reactant candidates: {len(reactant_list)}\")\n",
    "    print(f\"Reagent candidates: {len(reagent_list)}\")\n",
    "    print(f\"Product candidates: {len(product_list)}\")\n",
    "    print(f\"Known combinations: {len(product_dict)}\")\n",
    "    \n",
    "    return reactant_list, reagent_list, product_list, product_dict, true_yield_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2jviwc7axkj",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianOptimizationWithMCDropout:\n",
    "    def __init__(self, model, tokenizer, reactant_list, reagent_list, product_dict, true_yield_dict, n_mc_samples=50):\n",
    "        \"\"\"\n",
    "        MC Dropoutを使用したベイズ最適化（reactant-reagent組み合わせ探索）\n",
    "        \n",
    "        Args:\n",
    "            model: 学習済みReactionT5Yieldモデル\n",
    "            tokenizer: トークナイザー\n",
    "            reactant_list: reactantの候補リスト\n",
    "            reagent_list: reagentの候補リスト\n",
    "            product_dict: (reactant, reagent) -> product のマッピング辞書\n",
    "            true_yield_dict: (reactant, reagent, product) -> yield のマッピング辞書\n",
    "            n_mc_samples: MC Dropoutのサンプル数\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.reactant_list = reactant_list\n",
    "        self.reagent_list = reagent_list\n",
    "        self.product_dict = product_dict\n",
    "        self.true_yield_dict = true_yield_dict\n",
    "        self.n_mc_samples = n_mc_samples\n",
    "        \n",
    "        # 全ての有効な組み合わせを事前計算\n",
    "        self.valid_combinations = []\n",
    "        for reactant in reactant_list:\n",
    "            for reagent in reagent_list:\n",
    "                if (reactant, reagent) in product_dict:\n",
    "                    self.valid_combinations.append((reactant, reagent))\n",
    "        \n",
    "        print(f\"有効な組み合わせ数: {len(self.valid_combinations)}\")\n",
    "        \n",
    "        # 実験結果の記録\n",
    "        self.experiment_history = []\n",
    "        self.tried_combinations = set()\n",
    "    \n",
    "    def _predict_yield_with_uncertainty(self, reaction_smiles):\n",
    "        \"\"\"MC Dropoutによる収率予測\"\"\"\n",
    "        result = mc_dropout_inference(\n",
    "            self.model, self.tokenizer, reaction_smiles, \n",
    "            n_samples=self.n_mc_samples\n",
    "        )\n",
    "        return result['mean'], result['variance']\n",
    "    \n",
    "    def _acquisition_function(self, mean, variance, best_observed_yield, xi=0.01):\n",
    "        \"\"\"期待改善量（Expected Improvement）による獲得関数\"\"\"\n",
    "        if variance <= 0:\n",
    "            return 0.0\n",
    "        \n",
    "        std = np.sqrt(variance)\n",
    "        z = (mean - best_observed_yield - xi) / std\n",
    "        ei = (mean - best_observed_yield - xi) * norm.cdf(z) + std * norm.pdf(z)\n",
    "        return ei\n",
    "    \n",
    "    def _get_best_observed_yield(self):\n",
    "        \"\"\"これまでの最良収率を取得\"\"\"\n",
    "        if len(self.experiment_history) > 0:\n",
    "            return max([exp['actual_yield'] for exp in self.experiment_history])\n",
    "        else:\n",
    "            return 0.0\n",
    "    \n",
    "    def _select_next_candidate(self, exploration_prob=0.1):\n",
    "        \"\"\"獲得関数に基づいて次の候補を選択\"\"\"\n",
    "        # 未試行の組み合わせを取得\n",
    "        untried_combinations = [\n",
    "            combo for combo in self.valid_combinations \n",
    "            if combo not in self.tried_combinations\n",
    "        ]\n",
    "        \n",
    "        if not untried_combinations:\n",
    "            print(\"全ての組み合わせを試行済みです。\")\n",
    "            return None\n",
    "        \n",
    "        # 初期の数試行はランダムサンプリング\n",
    "        if len(self.experiment_history) < 3:\n",
    "            combo = np.random.choice(len(untried_combinations))\n",
    "            selected_combo = untried_combinations[combo]\n",
    "            print(f\"🎲 Random sampling: {selected_combo}\")\n",
    "            return selected_combo\n",
    "        \n",
    "        # 獲得関数を計算\n",
    "        best_yield = self._get_best_observed_yield()\n",
    "        acquisition_scores = []\n",
    "        \n",
    "        print(\"獲得関数値を計算中...\")\n",
    "        for reactant, reagent in untried_combinations:\n",
    "            product = self.product_dict[(reactant, reagent)]\n",
    "            reaction_smiles = f\"REACTANT:{reactant}REAGENT:{reagent}PRODUCT:{product}\"\n",
    "            \n",
    "            try:\n",
    "                pred_mean, pred_variance = self._predict_yield_with_uncertainty(reaction_smiles)\n",
    "                acq_value = self._acquisition_function(pred_mean, pred_variance, best_yield)\n",
    "                acquisition_scores.append({\n",
    "                    'combination': (reactant, reagent),\n",
    "                    'acquisition_value': acq_value,\n",
    "                    'predicted_mean': pred_mean,\n",
    "                    'predicted_variance': pred_variance\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error predicting {reactant} + {reagent}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if not acquisition_scores:\n",
    "            # 獲得関数が計算できない場合はランダム選択\n",
    "            combo = np.random.choice(len(untried_combinations))\n",
    "            return untried_combinations[combo]\n",
    "        \n",
    "        # 獲得関数値でソート\n",
    "        acquisition_scores.sort(key=lambda x: x['acquisition_value'], reverse=True)\n",
    "        \n",
    "        # ε-greedyの探索戦略\n",
    "        if np.random.random() < exploration_prob:\n",
    "            # 探索: ランダム選択\n",
    "            selected = np.random.choice(acquisition_scores)\n",
    "            print(f\"🎲 Exploration: {selected['combination']} (EI: {selected['acquisition_value']:.4f})\")\n",
    "        else:\n",
    "            # 活用: 最高獲得関数値を選択\n",
    "            selected = acquisition_scores[0]\n",
    "            print(f\"🎯 Exploitation: {selected['combination']} (EI: {selected['acquisition_value']:.4f})\")\n",
    "        \n",
    "        return selected['combination']\n",
    "    \n",
    "    def _evaluate_candidate(self, reactant, reagent, trial_num):\n",
    "        \"\"\"候補を評価（実験を実行）\"\"\"\n",
    "        product = self.product_dict[(reactant, reagent)]\n",
    "        reaction_smiles = f\"REACTANT:{reactant}REAGENT:{reagent}PRODUCT:{product}\"\n",
    "        \n",
    "        # MC Dropoutによる予測\n",
    "        try:\n",
    "            pred_mean, pred_variance = self._predict_yield_with_uncertainty(reaction_smiles)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Prediction error: {e}\")\n",
    "            return None\n",
    "        \n",
    "        # 実際の収率を取得\n",
    "        key = (reactant, reagent, product)\n",
    "        actual_yield = self.true_yield_dict.get(key)\n",
    "        \n",
    "        if actual_yield is None:\n",
    "            print(f\"❗ No ground truth for: {reactant} + {reagent} → {product}\")\n",
    "            actual_yield_pct = 0.0\n",
    "        else:\n",
    "            actual_yield_pct = actual_yield * 100  # パーセント変換\n",
    "        \n",
    "        # 獲得関数の計算\n",
    "        best_yield = self._get_best_observed_yield()\n",
    "        acquisition_value = self._acquisition_function(pred_mean, pred_variance, best_yield)\n",
    "        \n",
    "        # 誤差の計算\n",
    "        error_pct = pred_mean - actual_yield_pct if actual_yield is not None else None\n",
    "        \n",
    "        # 実験結果を記録\n",
    "        experiment_result = {\n",
    "            'trial': trial_num,\n",
    "            'reactant': reactant,\n",
    "            'reagent': reagent,\n",
    "            'product': product,\n",
    "            'reaction_smiles': reaction_smiles,\n",
    "            'predicted_mean': pred_mean,\n",
    "            'predicted_variance': pred_variance,\n",
    "            'actual_yield': actual_yield_pct,\n",
    "            'error_pct': error_pct,\n",
    "            'acquisition_value': acquisition_value\n",
    "        }\n",
    "        \n",
    "        # 出力\n",
    "        print(f\"🔎 Trial {trial_num}: {reactant} + {reagent} → {product}\")\n",
    "        print(f\"   📈 Predicted: {pred_mean:.2f}% ± {np.sqrt(pred_variance):.2f}%\")\n",
    "        print(f\"   🧪 Ground truth: {actual_yield_pct:.2f}%\" if actual_yield is not None else \"   🧪 Ground truth: None\")\n",
    "        if error_pct is not None:\n",
    "            print(f\"   ❗ Error: {error_pct:+.2f}%\")\n",
    "        print(f\"   🎯 Acquisition: {acquisition_value:.4f}\")\n",
    "        \n",
    "        return experiment_result\n",
    "    \n",
    "    def optimize(self, n_trials=50):\n",
    "        \"\"\"ベイズ最適化の実行\"\"\"\n",
    "        print(f\"ベイズ最適化を開始 ({n_trials}試行)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        for trial in range(1, n_trials + 1):\n",
    "            # 次の候補を選択\n",
    "            candidate = self._select_next_candidate()\n",
    "            if candidate is None:\n",
    "                print(\"全ての組み合わせを試行完了。\")\n",
    "                break\n",
    "            \n",
    "            reactant, reagent = candidate\n",
    "            \n",
    "            # 候補を評価\n",
    "            result = self._evaluate_candidate(reactant, reagent, trial)\n",
    "            if result is None:\n",
    "                continue\n",
    "            \n",
    "            # 結果を記録\n",
    "            self.experiment_history.append(result)\n",
    "            self.tried_combinations.add((reactant, reagent))\n",
    "            \n",
    "            # 進捗表示\n",
    "            current_best = max([exp['actual_yield'] for exp in self.experiment_history])\n",
    "            print(f\"   💡 Current best: {current_best:.2f}%\")\n",
    "            print(\"-\" * 60)\n",
    "        \n",
    "        print(f\"\\n最適化完了! 総試行数: {len(self.experiment_history)}\")\n",
    "        \n",
    "        # 最終結果\n",
    "        if self.experiment_history:\n",
    "            best_exp = max(self.experiment_history, key=lambda x: x['actual_yield'])\n",
    "            print(f\"🏆 最高収率: {best_exp['actual_yield']:.2f}%\")\n",
    "            print(f\"🏆 最適組み合わせ: {best_exp['reactant']} + {best_exp['reagent']} → {best_exp['product']}\")\n",
    "            return best_exp\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def get_best_experiments(self, top_k=5):\n",
    "        \"\"\"上位k個の実験結果を取得\"\"\"\n",
    "        sorted_experiments = sorted(\n",
    "            self.experiment_history, \n",
    "            key=lambda x: x['actual_yield'], \n",
    "            reverse=True\n",
    "        )\n",
    "        return sorted_experiments[:top_k]\n",
    "    \n",
    "    def get_optimization_summary(self):\n",
    "        \"\"\"最適化の概要統計を取得\"\"\"\n",
    "        if not self.experiment_history:\n",
    "            return {}\n",
    "        \n",
    "        actual_yields = [exp['actual_yield'] for exp in self.experiment_history]\n",
    "        predicted_means = [exp['predicted_mean'] for exp in self.experiment_history]\n",
    "        errors = [exp['error_pct'] for exp in self.experiment_history if exp['error_pct'] is not None]\n",
    "        \n",
    "        return {\n",
    "            'total_trials': len(self.experiment_history),\n",
    "            'max_yield': max(actual_yields),\n",
    "            'mean_yield': np.mean(actual_yields),\n",
    "            'std_yield': np.std(actual_yields),\n",
    "            'mae_error': np.mean(np.abs(errors)) if errors else None,\n",
    "            'rmse_error': np.sqrt(np.mean(np.array(errors)**2)) if errors else None,\n",
    "            'coverage': len(self.tried_combinations) / len(self.valid_combinations) * 100\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3uac2bboz",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reactant candidates: 25\n",
      "Reagent candidates: 23\n",
      "Product candidates: 23\n",
      "Known combinations: 543\n",
      "有効な組み合わせ数: 543\n"
     ]
    }
   ],
   "source": [
    "# 辞書の作成\n",
    "reactant_list, reagent_list, product_list, product_dict, true_yield_dict = create_reaction_dictionaries(df.head(1000))\n",
    "\n",
    "# ベイズ最適化器を初期化（新しいインターフェース）\n",
    "optimizer = BayesianOptimizationWithMCDropout(\n",
    "    model=yield_model,\n",
    "    tokenizer=yield_tokenizer,\n",
    "    reactant_list=reactant_list,\n",
    "    reagent_list=reagent_list,\n",
    "    product_dict=product_dict,\n",
    "    true_yield_dict=true_yield_dict,\n",
    "    n_mc_samples=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jkvnaq04w2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ベイズ最適化を開始 (30試行)\n",
      "============================================================\n",
      "🎲 Random sampling: ('COc1cc(Cl)ccc1F', 'CN(C)c1ccccc1-c1ccccc1P(c1ccccc1)c1ccccc1.OB(O)B(O)O')\n",
      "🔎 Trial 1: COc1cc(Cl)ccc1F + CN(C)c1ccccc1-c1ccccc1P(c1ccccc1)c1ccccc1.OB(O)B(O)O → COc1cc(B(O)O)ccc1F\n",
      "   📈 Predicted: 71.69% ± 1.71%\n",
      "   🧪 Ground truth: 30.78%\n",
      "   ❗ Error: +40.91%\n",
      "   🎯 Acquisition: 71.6821\n",
      "   💡 Current best: 30.78%\n",
      "------------------------------------------------------------\n",
      "🎲 Random sampling: ('Clc1ccc2[nH]ccc2c1', 'c1ccc(P(c2ccccc2)C2CCCCC2)cc1.OB(O)B(O)O')\n",
      "🔎 Trial 2: Clc1ccc2[nH]ccc2c1 + c1ccc(P(c2ccccc2)C2CCCCC2)cc1.OB(O)B(O)O → OB(O)c1ccc2[nH]ccc2c1\n",
      "   📈 Predicted: 73.39% ± 1.29%\n",
      "   🧪 Ground truth: 46.13%\n",
      "   ❗ Error: +27.26%\n",
      "   🎯 Acquisition: 42.6040\n",
      "   💡 Current best: 46.13%\n",
      "------------------------------------------------------------\n",
      "🎲 Random sampling: ('Brc1ccc2c(c1)OCO2', 'c1ccc(-c2ccccc2P(C2CCCCC2)C2CCCCC2)cc1.OB(O)B(O)O')\n",
      "🔎 Trial 3: Brc1ccc2c(c1)OCO2 + c1ccc(-c2ccccc2P(C2CCCCC2)C2CCCCC2)cc1.OB(O)B(O)O → OB(O)c1ccc2c(c1)OCO2\n",
      "   📈 Predicted: 72.39% ± 1.88%\n",
      "   🧪 Ground truth: 70.74%\n",
      "   ❗ Error: +1.65%\n",
      "   🎯 Acquisition: 26.2538\n",
      "   💡 Current best: 70.74%\n",
      "------------------------------------------------------------\n",
      "獲得関数値を計算中...\n",
      "🎯 Exploitation: ('Cc1nc2cc(OS(=O)(=O)N(C)C)ccc2s1', 'c1ccc(-n2cccc2P(C2CCCCC2)C2CCCCC2)cc1.OB(O)B(O)O') (EI: 8.3218)\n",
      "🔎 Trial 4: Cc1nc2cc(OS(=O)(=O)N(C)C)ccc2s1 + c1ccc(-n2cccc2P(C2CCCCC2)C2CCCCC2)cc1.OB(O)B(O)O → Cc1nc2cc(B(O)O)ccc2s1\n",
      "   📈 Predicted: 79.10% ± 0.86%\n",
      "   🧪 Ground truth: 0.10%\n",
      "   ❗ Error: +79.00%\n",
      "   🎯 Acquisition: 8.3531\n",
      "   💡 Current best: 70.74%\n",
      "------------------------------------------------------------\n",
      "獲得関数値を計算中...\n"
     ]
    }
   ],
   "source": [
    "# ベイズ最適化の実行\n",
    "best_result = optimizer.optimize(n_trials=30)\n",
    "\n",
    "# 最適化の概要統計を表示\n",
    "summary = optimizer.get_optimization_summary()\n",
    "print(f\"\\n=== 最適化概要 ===\")\n",
    "print(f\"総試行数: {summary.get('total_trials', 0)}\")\n",
    "print(f\"最高収率: {summary.get('max_yield', 0):.2f}%\")\n",
    "print(f\"平均収率: {summary.get('mean_yield', 0):.2f}%\")\n",
    "print(f\"収率標準偏差: {summary.get('std_yield', 0):.2f}%\")\n",
    "if summary.get('mae_error'):\n",
    "    print(f\"予測誤差 (MAE): {summary['mae_error']:.2f}%\")\n",
    "    print(f\"予測誤差 (RMSE): {summary['rmse_error']:.2f}%\")\n",
    "print(f\"探索範囲: {summary.get('coverage', 0):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4247de",
   "metadata": {},
   "source": [
    "## 可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rp1kyuwkxx",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_optimization_results(experiment_history, out_dir=None, show=True, dpi=180):\n",
    "    \"\"\"\n",
    "    最適化結果の可視化（greedy_optuna.ipynbのvisualize_logs関数を参考）\n",
    "    \n",
    "    Args:\n",
    "        experiment_history: 実験履歴のリスト\n",
    "        out_dir: 出力ディレクトリ\n",
    "        show: グラフを表示するかどうか\n",
    "        dpi: 解像度\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    if not experiment_history:\n",
    "        print(\"実験データがありません。\")\n",
    "        return\n",
    "    \n",
    "    # 出力ディレクトリの準備\n",
    "    if out_dir:\n",
    "        save_dir = os.path.join(out_dir, \"visualization\")\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "    else:\n",
    "        save_dir = None\n",
    "    \n",
    "    # データの準備\n",
    "    trials = [exp['trial'] for exp in experiment_history]\n",
    "    actual_yields = [exp['actual_yield'] for exp in experiment_history]\n",
    "    predicted_means = [exp['predicted_mean'] for exp in experiment_history]\n",
    "    predicted_stds = [np.sqrt(exp['predicted_variance']) for exp in experiment_history]\n",
    "    errors = [exp['error_pct'] for exp in experiment_history if exp['error_pct'] is not None]\n",
    "    \n",
    "    # 累積最大値を計算\n",
    "    cumulative_max = np.maximum.accumulate(actual_yields)\n",
    "    \n",
    "    # 全体指標の計算\n",
    "    if len(actual_yields) > 0 and len(errors) > 0:\n",
    "        mae_pct = np.mean(np.abs(errors))\n",
    "        rmse_pct = np.sqrt(np.mean(np.array(errors)**2))\n",
    "        bias_pct = np.mean(errors)\n",
    "        \n",
    "        print(f\"=== 全体指標 ===\")\n",
    "        print(f\"試行数: {len(experiment_history)}\")\n",
    "        print(f\"MAE: {mae_pct:.2f}%\")\n",
    "        print(f\"RMSE: {rmse_pct:.2f}%\")\n",
    "        print(f\"Bias: {bias_pct:+.2f}%\")\n",
    "        print(f\"最高収率: {max(actual_yields):.2f}%\")\n",
    "    \n",
    "    # 図の作成\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # 1. パリティプロット（予測 vs 実測）\n",
    "    ax = axes[0, 0]\n",
    "    ax.errorbar(predicted_means, actual_yields, xerr=predicted_stds, \n",
    "               fmt='o', alpha=0.6, capsize=3)\n",
    "    ax.plot([0, 100], [0, 100], 'r--', label='Perfect Prediction')\n",
    "    ax.set_xlabel('Predicted Yield (%)')\n",
    "    ax.set_ylabel('Actual Yield (%)')\n",
    "    ax.set_title('Parity: Prediction vs Truth')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. 最適化の進行\n",
    "    ax = axes[0, 1]\n",
    "    ax.plot(trials, actual_yields, 'o-', alpha=0.6, label='Actual Yield', markersize=4)\n",
    "    ax.plot(trials, cumulative_max, 'r-', linewidth=2, label='Best So Far')\n",
    "    ax.set_xlabel('Trial')\n",
    "    ax.set_ylabel('Yield (%)')\n",
    "    ax.set_title('Optimization Progress')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. 不確実性 vs 実測収率\n",
    "    ax = axes[0, 2]\n",
    "    ax.scatter(predicted_stds, actual_yields, alpha=0.6)\n",
    "    ax.set_xlabel('Prediction Uncertainty (Std)')\n",
    "    ax.set_ylabel('Actual Yield (%)')\n",
    "    ax.set_title('Uncertainty vs Actual Yield')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. 誤差ヒストグラム\n",
    "    ax = axes[1, 0]\n",
    "    if errors:\n",
    "        ax.hist(errors, bins=20, alpha=0.7, edgecolor='black')\n",
    "        ax.axvline(0, color='red', linestyle='--', label='Perfect Prediction')\n",
    "        ax.set_xlabel('Prediction Error (pred - true) [%]')\n",
    "        ax.set_ylabel('Count')\n",
    "        ax.set_title('Error Histogram')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. 予測収率の分布\n",
    "    ax = axes[1, 1]\n",
    "    ax.hist(predicted_means, bins=20, alpha=0.5, label='Predicted', edgecolor='black')\n",
    "    ax.hist(actual_yields, bins=20, alpha=0.5, label='Actual', edgecolor='black')\n",
    "    ax.set_xlabel('Yield (%)')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('Yield Distribution')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. 収率 vs 試行番号（散布図）\n",
    "    ax = axes[1, 2]\n",
    "    ax.scatter(trials, predicted_means, alpha=0.5, label='Predicted', s=20)\n",
    "    ax.scatter(trials, actual_yields, alpha=0.5, label='Actual', s=20)\n",
    "    ax.set_xlabel('Trial')\n",
    "    ax.set_ylabel('Yield (%)')\n",
    "    ax.set_title('Yields over Trials')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 保存\n",
    "    if save_dir:\n",
    "        fig.savefig(os.path.join(save_dir, \"optimization_results.png\"), \n",
    "                   dpi=dpi, bbox_inches=\"tight\")\n",
    "        print(f\"図を保存しました: {save_dir}/optimization_results.png\")\n",
    "    \n",
    "    if show:\n",
    "        plt.show()\n",
    "    \n",
    "    plt.close(fig)\n",
    "    \n",
    "    return {\n",
    "        'mae_pct': mae_pct if errors else None,\n",
    "        'rmse_pct': rmse_pct if errors else None,\n",
    "        'bias_pct': bias_pct if errors else None,\n",
    "        'max_yield': max(actual_yields) if actual_yields else None,\n",
    "        'save_dir': save_dir\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbb64e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果の可視化（新しいプロット関数を使用）\n",
    "results = visualize_optimization_results(optimizer.experiment_history, show=True)\n",
    "\n",
    "# 上位5つの実験結果を表示\n",
    "print(\"\\n=== 上位5つの実験結果 ===\")\n",
    "best_experiments = optimizer.get_best_experiments(top_k=5)\n",
    "for i, exp in enumerate(best_experiments, 1):\n",
    "    print(f\"\\n{i}位: 試行{exp['trial'] + 1}\")\n",
    "    print(f\"  Reactant: {exp['reactant']}\")\n",
    "    print(f\"  Reagent: {exp['reagent']}\")\n",
    "    print(f\"  Product: {exp['product']}\")\n",
    "    print(f\"  実際の収率: {exp['actual_yield']:.2f}%\")\n",
    "    print(f\"  予測収率: {exp['predicted_mean']:.2f}% ± {np.sqrt(exp['predicted_variance']):.2f}%\")\n",
    "    if exp['error_pct'] is not None:\n",
    "        print(f\"  誤差: {exp['error_pct']:+.2f}%\")\n",
    "    print(f\"  獲得関数値: {exp['acquisition_value']:.4f}\")\n",
    "\n",
    "# reactant-reagent組み合わせの統計情報\n",
    "print(\"\\n=== Reactant-Reagent組み合わせ統計 ===\")\n",
    "combo_stats = optimizer.get_combination_statistics()\n",
    "print(f\"探索された組み合わせ数: {len(combo_stats)}\")\n",
    "\n",
    "# 最も多く選ばれた組み合わせ上位3つ\n",
    "combo_counts = {combo: len(data) for combo, data in combo_stats.items()}\n",
    "top_combos = sorted(combo_counts.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "\n",
    "print(\"\\n最も多く探索された組み合わせ:\")\n",
    "for i, ((reactant, reagent), count) in enumerate(top_combos, 1):\n",
    "    avg_yield = np.mean([d['actual_yield'] for d in combo_stats[(reactant, reagent)]])\n",
    "    print(f\"  {i}. {reactant} + {reagent}: {count}回, 平均収率: {avg_yield:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
