{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "399f6a19",
   "metadata": {},
   "source": [
    "## ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "474abd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad075c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def space_clean(row):\n",
    "    row = row.replace(\". \", \"\").replace(\" .\", \"\").replace(\"  \", \" \")\n",
    "    return row\n",
    "\n",
    "\n",
    "def canonicalize(smiles):\n",
    "    try:\n",
    "        new_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles), canonical=True)\n",
    "    except:\n",
    "        new_smiles = None\n",
    "    return new_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b6b1767",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/inchi_23l_reaction_t5_ready.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8190d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿…é ˆã‚«ãƒ©ãƒ ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯ã¨è£œå®Œ\n",
    "required_cols = [\"REACTANT\", \"CATALYST\", \"REAGENT\", \"SOLVENT\", \"PRODUCT\"]\n",
    "for col in required_cols:\n",
    "    if col not in df.columns:\n",
    "        df[col] = \"\"\n",
    "\n",
    "# å¿…è¦ã«å¿œã˜ã¦YIELDã‚’æ¨™æº–åŒ–ï¼ˆ0-1ã«æ­£è¦åŒ–ï¼‰\n",
    "if \"YIELD\" in df.columns and df[\"YIELD\"].max() >= 100:\n",
    "    df[\"YIELD\"] = df[\"YIELD\"].clip(0, 100) / 100\n",
    "else:\n",
    "    df[\"YIELD\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "786c0f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"REAGENT\", \"REACTANT\", \"PRODUCT\"]:\n",
    "    df[col] = df[col].apply(space_clean)\n",
    "    df[col] = df[col].apply(lambda x: canonicalize(x) if x != \" \" else \" \")\n",
    "    df = df[~df[col].isna()].reset_index(drop=True)\n",
    "    df[col] = df[col].apply(lambda x: \".\".join(sorted(x.split(\".\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "130c5fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"REAGENT\"] = df[\"CATALYST\"].fillna(\" \") + \".\" + df[\"REAGENT\"].fillna(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a03ecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df[[\"YIELD\"]].drop_duplicates().index].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74faba6",
   "metadata": {},
   "source": [
    "## ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b32b72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/ReactionT5-bo-yield/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, T5ForConditionalGeneration, AutoConfig, PreTrainedModel\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a161557",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReactionT5Yield(PreTrainedModel):\n",
    "    config_class  = AutoConfig\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(self.config._name_or_path)\n",
    "        self.model.resize_token_embeddings(self.config.vocab_size)\n",
    "        self.fc1 = nn.Linear(self.config.hidden_size, self.config.hidden_size//2)\n",
    "        self.fc2 = nn.Linear(self.config.hidden_size, self.config.hidden_size//2)\n",
    "        self.fc3 = nn.Linear(self.config.hidden_size//2*2, self.config.hidden_size)\n",
    "        self.fc4 = nn.Linear(self.config.hidden_size, self.config.hidden_size)\n",
    "        self.fc5 = nn.Linear(self.config.hidden_size, 1)\n",
    "\n",
    "        self._init_weights(self.fc1)\n",
    "        self._init_weights(self.fc2)\n",
    "        self._init_weights(self.fc3)\n",
    "        self._init_weights(self.fc4)\n",
    "        self._init_weights(self.fc5)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.01)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.01)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        device = inputs['input_ids'].device\n",
    "\n",
    "        with torch.no_grad():\n",
    "            encoder_outputs = self.model.encoder(\n",
    "                input_ids=inputs['input_ids'],\n",
    "                attention_mask=inputs.get('attention_mask', None),\n",
    "            )\n",
    "            encoder_hidden_states = encoder_outputs[0]  # (B, L, H)\n",
    "\n",
    "            dec_input_ids = torch.full(\n",
    "                (inputs['input_ids'].size(0), 1),\n",
    "                self.config.decoder_start_token_id,\n",
    "                dtype=torch.long,\n",
    "                device=device,\n",
    "            )\n",
    "\n",
    "            outputs = self.model.decoder(\n",
    "                input_ids=dec_input_ids,\n",
    "                encoder_hidden_states=encoder_hidden_states,\n",
    "            )\n",
    "            last_hidden_states = outputs[0]  # (B, 1, H)\n",
    "\n",
    "        output1 = self.fc1(last_hidden_states.view(-1, self.config.hidden_size))\n",
    "        output2 = self.fc2(encoder_hidden_states[:, 0, :].view(-1, self.config.hidden_size))\n",
    "        output = self.fc3(torch.hstack((output1, output2)))\n",
    "        output = self.fc4(output)\n",
    "        output = self.fc5(output)\n",
    "        return output * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f496cef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åç‡äºˆæ¸¬ï¼ˆã‚¹ã‚«ãƒ©ãƒ¼å‡ºåŠ›ï¼‰\n",
    "yield_tokenizer = AutoTokenizer.from_pretrained(\"sagawa/ReactionT5v2-yield\")\n",
    "yield_model = ReactionT5Yield.from_pretrained(\"sagawa/ReactionT5v2-yield\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82f5b903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropoutãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚’å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ã«è¨­å®šã™ã‚‹é–¢æ•°\n",
    "def enable_dropout(model):\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.Dropout):\n",
    "            module.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0742088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MC Dropoutã«ã‚ˆã‚‹æ¨è«–\n",
    "def mc_dropout_inference(model, tokenizer, reaction_smiles, n_samples=100, max_length=512):\n",
    "    model.eval()  # ã¾ãšãƒ¢ãƒ‡ãƒ«å…¨ä½“ã‚’è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã«\n",
    "    enable_dropout(model)  # Dropoutãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ã¿å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰ã«\n",
    "    \n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    # å˜ä¸€ã®æ–‡å­—åˆ—ã®å ´åˆãƒªã‚¹ãƒˆã«å¤‰æ›\n",
    "    if isinstance(reaction_smiles, str):\n",
    "        reaction_smiles = [reaction_smiles]\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(n_samples):\n",
    "            batch_predictions = []\n",
    "            \n",
    "            for smiles in reaction_smiles:\n",
    "                # ãƒˆãƒ¼ã‚¯ãƒ³åŒ–\n",
    "                inputs = tokenizer(\n",
    "                    smiles, \n",
    "                    return_tensors=\"pt\", \n",
    "                    max_length=max_length,\n",
    "                    padding=True,\n",
    "                    truncation=True\n",
    "                ).to(device)\n",
    "                \n",
    "                # äºˆæ¸¬å®Ÿè¡Œ\n",
    "                output = model(inputs)\n",
    "                batch_predictions.append(output.cpu().numpy().flatten())\n",
    "            \n",
    "            predictions.append(np.array(batch_predictions))\n",
    "    \n",
    "    # çµæœã‚’é…åˆ—ã«å¤‰æ›: (n_samples, n_reactions)\n",
    "    predictions = np.array(predictions)\n",
    "    \n",
    "    # çµ±è¨ˆé‡è¨ˆç®—\n",
    "    mean_pred = np.mean(predictions, axis=0)\n",
    "    var_pred = np.var(predictions, axis=0)\n",
    "    \n",
    "    if len(reaction_smiles) == 1:\n",
    "        return {\n",
    "            'mean': float(mean_pred[0]),\n",
    "            'variance': float(var_pred[0])\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            'mean': mean_pred.tolist(),\n",
    "            'variance': var_pred.tolist()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce704e3e",
   "metadata": {},
   "source": [
    "## ãƒ™ã‚¤ã‚ºæœ€é©åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9zyzrfudbg",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d1uliljyvxh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¾æ›¸ä½œæˆé–¢æ•°\n",
    "def create_reaction_dictionaries(df):\n",
    "    \"\"\"\n",
    "    ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰åå¿œè¾æ›¸ã‚’ä½œæˆ\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (reactant_list, reagent_list, product_list, product_dict, true_yield_dict)\n",
    "    \"\"\"\n",
    "    reactant_list = sorted(df[\"REACTANT\"].unique())\n",
    "    reagent_list = sorted(df[\"REAGENT\"].unique())\n",
    "    product_list = sorted(df[\"PRODUCT\"].unique())\n",
    "    \n",
    "    # (reactant, reagent) -> product ã®ãƒãƒƒãƒ”ãƒ³ã‚°\n",
    "    product_dict = {\n",
    "        (row[\"REACTANT\"], row[\"REAGENT\"]): row[\"PRODUCT\"]\n",
    "        for _, row in df.iterrows()\n",
    "    }\n",
    "    \n",
    "    # (reactant, reagent, product) -> yield ã®ãƒãƒƒãƒ”ãƒ³ã‚°\n",
    "    true_yield_dict = {\n",
    "        (row[\"REACTANT\"], row[\"REAGENT\"], row[\"PRODUCT\"]): row[\"YIELD\"]\n",
    "        for _, row in df.iterrows()\n",
    "    }\n",
    "    \n",
    "    print(f\"Reactant candidates: {len(reactant_list)}\")\n",
    "    print(f\"Reagent candidates: {len(reagent_list)}\")\n",
    "    print(f\"Product candidates: {len(product_list)}\")\n",
    "    print(f\"Known combinations: {len(product_dict)}\")\n",
    "    \n",
    "    return reactant_list, reagent_list, product_list, product_dict, true_yield_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2jviwc7axkj",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianOptimizationWithMCDropout:\n",
    "    def __init__(self, model, tokenizer, reactant_list, reagent_list, product_dict, true_yield_dict, n_mc_samples=50):\n",
    "        \"\"\"\n",
    "        MC Dropoutã‚’ä½¿ç”¨ã—ãŸãƒ™ã‚¤ã‚ºæœ€é©åŒ–ï¼ˆreactant-reagentçµ„ã¿åˆã‚ã›æ¢ç´¢ï¼‰\n",
    "        \n",
    "        Args:\n",
    "            model: å­¦ç¿’æ¸ˆã¿ReactionT5Yieldãƒ¢ãƒ‡ãƒ«\n",
    "            tokenizer: ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼\n",
    "            reactant_list: reactantã®å€™è£œãƒªã‚¹ãƒˆ\n",
    "            reagent_list: reagentã®å€™è£œãƒªã‚¹ãƒˆ\n",
    "            product_dict: (reactant, reagent) -> product ã®ãƒãƒƒãƒ”ãƒ³ã‚°è¾æ›¸\n",
    "            true_yield_dict: (reactant, reagent, product) -> yield ã®ãƒãƒƒãƒ”ãƒ³ã‚°è¾æ›¸\n",
    "            n_mc_samples: MC Dropoutã®ã‚µãƒ³ãƒ—ãƒ«æ•°\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.reactant_list = reactant_list\n",
    "        self.reagent_list = reagent_list\n",
    "        self.product_dict = product_dict\n",
    "        self.true_yield_dict = true_yield_dict\n",
    "        self.n_mc_samples = n_mc_samples\n",
    "        \n",
    "        # å…¨ã¦ã®æœ‰åŠ¹ãªçµ„ã¿åˆã‚ã›ã‚’äº‹å‰è¨ˆç®—\n",
    "        self.valid_combinations = []\n",
    "        for reactant in reactant_list:\n",
    "            for reagent in reagent_list:\n",
    "                if (reactant, reagent) in product_dict:\n",
    "                    self.valid_combinations.append((reactant, reagent))\n",
    "        \n",
    "        print(f\"æœ‰åŠ¹ãªçµ„ã¿åˆã‚ã›æ•°: {len(self.valid_combinations)}\")\n",
    "        \n",
    "        # å®Ÿé¨“çµæœã®è¨˜éŒ²\n",
    "        self.experiment_history = []\n",
    "        self.tried_combinations = set()\n",
    "    \n",
    "    def _predict_yield_with_uncertainty(self, reaction_smiles):\n",
    "        \"\"\"MC Dropoutã«ã‚ˆã‚‹åç‡äºˆæ¸¬\"\"\"\n",
    "        result = mc_dropout_inference(\n",
    "            self.model, self.tokenizer, reaction_smiles, \n",
    "            n_samples=self.n_mc_samples\n",
    "        )\n",
    "        return result['mean'], result['variance']\n",
    "    \n",
    "    def _acquisition_function(self, mean, variance, best_observed_yield, xi=0.01):\n",
    "        \"\"\"æœŸå¾…æ”¹å–„é‡ï¼ˆExpected Improvementï¼‰ã«ã‚ˆã‚‹ç²å¾—é–¢æ•°\"\"\"\n",
    "        if variance <= 0:\n",
    "            return 0.0\n",
    "        \n",
    "        std = np.sqrt(variance)\n",
    "        z = (mean - best_observed_yield - xi) / std\n",
    "        ei = (mean - best_observed_yield - xi) * norm.cdf(z) + std * norm.pdf(z)\n",
    "        return ei\n",
    "    \n",
    "    def _get_best_observed_yield(self):\n",
    "        \"\"\"ã“ã‚Œã¾ã§ã®æœ€è‰¯åç‡ã‚’å–å¾—\"\"\"\n",
    "        if len(self.experiment_history) > 0:\n",
    "            return max([exp['actual_yield'] for exp in self.experiment_history])\n",
    "        else:\n",
    "            return 0.0\n",
    "    \n",
    "    def _select_next_candidate(self, exploration_prob=0.1):\n",
    "        \"\"\"ç²å¾—é–¢æ•°ã«åŸºã¥ã„ã¦æ¬¡ã®å€™è£œã‚’é¸æŠ\"\"\"\n",
    "        # æœªè©¦è¡Œã®çµ„ã¿åˆã‚ã›ã‚’å–å¾—\n",
    "        untried_combinations = [\n",
    "            combo for combo in self.valid_combinations \n",
    "            if combo not in self.tried_combinations\n",
    "        ]\n",
    "        \n",
    "        if not untried_combinations:\n",
    "            print(\"å…¨ã¦ã®çµ„ã¿åˆã‚ã›ã‚’è©¦è¡Œæ¸ˆã¿ã§ã™ã€‚\")\n",
    "            return None\n",
    "        \n",
    "        # åˆæœŸã®æ•°è©¦è¡Œã¯ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°\n",
    "        if len(self.experiment_history) < 3:\n",
    "            combo = np.random.choice(len(untried_combinations))\n",
    "            selected_combo = untried_combinations[combo]\n",
    "            print(f\"ğŸ² Random sampling: {selected_combo}\")\n",
    "            return selected_combo\n",
    "        \n",
    "        # ç²å¾—é–¢æ•°ã‚’è¨ˆç®—\n",
    "        best_yield = self._get_best_observed_yield()\n",
    "        acquisition_scores = []\n",
    "        \n",
    "        print(\"ç²å¾—é–¢æ•°å€¤ã‚’è¨ˆç®—ä¸­...\")\n",
    "        for reactant, reagent in untried_combinations:\n",
    "            product = self.product_dict[(reactant, reagent)]\n",
    "            reaction_smiles = f\"REACTANT:{reactant}REAGENT:{reagent}PRODUCT:{product}\"\n",
    "            \n",
    "            try:\n",
    "                pred_mean, pred_variance = self._predict_yield_with_uncertainty(reaction_smiles)\n",
    "                acq_value = self._acquisition_function(pred_mean, pred_variance, best_yield)\n",
    "                acquisition_scores.append({\n",
    "                    'combination': (reactant, reagent),\n",
    "                    'acquisition_value': acq_value,\n",
    "                    'predicted_mean': pred_mean,\n",
    "                    'predicted_variance': pred_variance\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error predicting {reactant} + {reagent}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if not acquisition_scores:\n",
    "            # ç²å¾—é–¢æ•°ãŒè¨ˆç®—ã§ããªã„å ´åˆã¯ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ\n",
    "            combo = np.random.choice(len(untried_combinations))\n",
    "            return untried_combinations[combo]\n",
    "        \n",
    "        # ç²å¾—é–¢æ•°å€¤ã§ã‚½ãƒ¼ãƒˆ\n",
    "        acquisition_scores.sort(key=lambda x: x['acquisition_value'], reverse=True)\n",
    "        \n",
    "        # Îµ-greedyã®æ¢ç´¢æˆ¦ç•¥\n",
    "        if np.random.random() < exploration_prob:\n",
    "            # æ¢ç´¢: ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ\n",
    "            selected = np.random.choice(acquisition_scores)\n",
    "            print(f\"ğŸ² Exploration: {selected['combination']} (EI: {selected['acquisition_value']:.4f})\")\n",
    "        else:\n",
    "            # æ´»ç”¨: æœ€é«˜ç²å¾—é–¢æ•°å€¤ã‚’é¸æŠ\n",
    "            selected = acquisition_scores[0]\n",
    "            print(f\"ğŸ¯ Exploitation: {selected['combination']} (EI: {selected['acquisition_value']:.4f})\")\n",
    "        \n",
    "        return selected['combination']\n",
    "    \n",
    "    def _evaluate_candidate(self, reactant, reagent, trial_num):\n",
    "        \"\"\"å€™è£œã‚’è©•ä¾¡ï¼ˆå®Ÿé¨“ã‚’å®Ÿè¡Œï¼‰\"\"\"\n",
    "        product = self.product_dict[(reactant, reagent)]\n",
    "        reaction_smiles = f\"REACTANT:{reactant}REAGENT:{reagent}PRODUCT:{product}\"\n",
    "        \n",
    "        # MC Dropoutã«ã‚ˆã‚‹äºˆæ¸¬\n",
    "        try:\n",
    "            pred_mean, pred_variance = self._predict_yield_with_uncertainty(reaction_smiles)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Prediction error: {e}\")\n",
    "            return None\n",
    "        \n",
    "        # å®Ÿéš›ã®åç‡ã‚’å–å¾—\n",
    "        key = (reactant, reagent, product)\n",
    "        actual_yield = self.true_yield_dict.get(key)\n",
    "        \n",
    "        if actual_yield is None:\n",
    "            print(f\"â— No ground truth for: {reactant} + {reagent} â†’ {product}\")\n",
    "            actual_yield_pct = 0.0\n",
    "        else:\n",
    "            actual_yield_pct = actual_yield * 100  # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆå¤‰æ›\n",
    "        \n",
    "        # ç²å¾—é–¢æ•°ã®è¨ˆç®—\n",
    "        best_yield = self._get_best_observed_yield()\n",
    "        acquisition_value = self._acquisition_function(pred_mean, pred_variance, best_yield)\n",
    "        \n",
    "        # èª¤å·®ã®è¨ˆç®—\n",
    "        error_pct = pred_mean - actual_yield_pct if actual_yield is not None else None\n",
    "        \n",
    "        # å®Ÿé¨“çµæœã‚’è¨˜éŒ²\n",
    "        experiment_result = {\n",
    "            'trial': trial_num,\n",
    "            'reactant': reactant,\n",
    "            'reagent': reagent,\n",
    "            'product': product,\n",
    "            'reaction_smiles': reaction_smiles,\n",
    "            'predicted_mean': pred_mean,\n",
    "            'predicted_variance': pred_variance,\n",
    "            'actual_yield': actual_yield_pct,\n",
    "            'error_pct': error_pct,\n",
    "            'acquisition_value': acquisition_value\n",
    "        }\n",
    "        \n",
    "        # å‡ºåŠ›\n",
    "        print(f\"ğŸ” Trial {trial_num}: {reactant} + {reagent} â†’ {product}\")\n",
    "        print(f\"   ğŸ“ˆ Predicted: {pred_mean:.2f}% Â± {np.sqrt(pred_variance):.2f}%\")\n",
    "        print(f\"   ğŸ§ª Ground truth: {actual_yield_pct:.2f}%\" if actual_yield is not None else \"   ğŸ§ª Ground truth: None\")\n",
    "        if error_pct is not None:\n",
    "            print(f\"   â— Error: {error_pct:+.2f}%\")\n",
    "        print(f\"   ğŸ¯ Acquisition: {acquisition_value:.4f}\")\n",
    "        \n",
    "        return experiment_result\n",
    "    \n",
    "    def optimize(self, n_trials=50):\n",
    "        \"\"\"ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®å®Ÿè¡Œ\"\"\"\n",
    "        print(f\"ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã‚’é–‹å§‹ ({n_trials}è©¦è¡Œ)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        for trial in range(1, n_trials + 1):\n",
    "            # æ¬¡ã®å€™è£œã‚’é¸æŠ\n",
    "            candidate = self._select_next_candidate()\n",
    "            if candidate is None:\n",
    "                print(\"å…¨ã¦ã®çµ„ã¿åˆã‚ã›ã‚’è©¦è¡Œå®Œäº†ã€‚\")\n",
    "                break\n",
    "            \n",
    "            reactant, reagent = candidate\n",
    "            \n",
    "            # å€™è£œã‚’è©•ä¾¡\n",
    "            result = self._evaluate_candidate(reactant, reagent, trial)\n",
    "            if result is None:\n",
    "                continue\n",
    "            \n",
    "            # çµæœã‚’è¨˜éŒ²\n",
    "            self.experiment_history.append(result)\n",
    "            self.tried_combinations.add((reactant, reagent))\n",
    "            \n",
    "            # é€²æ—è¡¨ç¤º\n",
    "            current_best = max([exp['actual_yield'] for exp in self.experiment_history])\n",
    "            print(f\"   ğŸ’¡ Current best: {current_best:.2f}%\")\n",
    "            print(\"-\" * 60)\n",
    "        \n",
    "        print(f\"\\næœ€é©åŒ–å®Œäº†! ç·è©¦è¡Œæ•°: {len(self.experiment_history)}\")\n",
    "        \n",
    "        # æœ€çµ‚çµæœ\n",
    "        if self.experiment_history:\n",
    "            best_exp = max(self.experiment_history, key=lambda x: x['actual_yield'])\n",
    "            print(f\"ğŸ† æœ€é«˜åç‡: {best_exp['actual_yield']:.2f}%\")\n",
    "            print(f\"ğŸ† æœ€é©çµ„ã¿åˆã‚ã›: {best_exp['reactant']} + {best_exp['reagent']} â†’ {best_exp['product']}\")\n",
    "            return best_exp\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def get_best_experiments(self, top_k=5):\n",
    "        \"\"\"ä¸Šä½kå€‹ã®å®Ÿé¨“çµæœã‚’å–å¾—\"\"\"\n",
    "        sorted_experiments = sorted(\n",
    "            self.experiment_history, \n",
    "            key=lambda x: x['actual_yield'], \n",
    "            reverse=True\n",
    "        )\n",
    "        return sorted_experiments[:top_k]\n",
    "    \n",
    "    def get_optimization_summary(self):\n",
    "        \"\"\"æœ€é©åŒ–ã®æ¦‚è¦çµ±è¨ˆã‚’å–å¾—\"\"\"\n",
    "        if not self.experiment_history:\n",
    "            return {}\n",
    "        \n",
    "        actual_yields = [exp['actual_yield'] for exp in self.experiment_history]\n",
    "        predicted_means = [exp['predicted_mean'] for exp in self.experiment_history]\n",
    "        errors = [exp['error_pct'] for exp in self.experiment_history if exp['error_pct'] is not None]\n",
    "        \n",
    "        return {\n",
    "            'total_trials': len(self.experiment_history),\n",
    "            'max_yield': max(actual_yields),\n",
    "            'mean_yield': np.mean(actual_yields),\n",
    "            'std_yield': np.std(actual_yields),\n",
    "            'mae_error': np.mean(np.abs(errors)) if errors else None,\n",
    "            'rmse_error': np.sqrt(np.mean(np.array(errors)**2)) if errors else None,\n",
    "            'coverage': len(self.tried_combinations) / len(self.valid_combinations) * 100\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3uac2bboz",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reactant candidates: 25\n",
      "Reagent candidates: 23\n",
      "Product candidates: 23\n",
      "Known combinations: 543\n",
      "æœ‰åŠ¹ãªçµ„ã¿åˆã‚ã›æ•°: 543\n"
     ]
    }
   ],
   "source": [
    "# è¾æ›¸ã®ä½œæˆ\n",
    "reactant_list, reagent_list, product_list, product_dict, true_yield_dict = create_reaction_dictionaries(df.head(1000))\n",
    "\n",
    "# ãƒ™ã‚¤ã‚ºæœ€é©åŒ–å™¨ã‚’åˆæœŸåŒ–ï¼ˆæ–°ã—ã„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼‰\n",
    "optimizer = BayesianOptimizationWithMCDropout(\n",
    "    model=yield_model,\n",
    "    tokenizer=yield_tokenizer,\n",
    "    reactant_list=reactant_list,\n",
    "    reagent_list=reagent_list,\n",
    "    product_dict=product_dict,\n",
    "    true_yield_dict=true_yield_dict,\n",
    "    n_mc_samples=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jkvnaq04w2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã‚’é–‹å§‹ (30è©¦è¡Œ)\n",
      "============================================================\n",
      "ğŸ² Random sampling: ('COc1cc(Cl)ccc1F', 'CN(C)c1ccccc1-c1ccccc1P(c1ccccc1)c1ccccc1.OB(O)B(O)O')\n",
      "ğŸ” Trial 1: COc1cc(Cl)ccc1F + CN(C)c1ccccc1-c1ccccc1P(c1ccccc1)c1ccccc1.OB(O)B(O)O â†’ COc1cc(B(O)O)ccc1F\n",
      "   ğŸ“ˆ Predicted: 71.69% Â± 1.71%\n",
      "   ğŸ§ª Ground truth: 30.78%\n",
      "   â— Error: +40.91%\n",
      "   ğŸ¯ Acquisition: 71.6821\n",
      "   ğŸ’¡ Current best: 30.78%\n",
      "------------------------------------------------------------\n",
      "ğŸ² Random sampling: ('Clc1ccc2[nH]ccc2c1', 'c1ccc(P(c2ccccc2)C2CCCCC2)cc1.OB(O)B(O)O')\n",
      "ğŸ” Trial 2: Clc1ccc2[nH]ccc2c1 + c1ccc(P(c2ccccc2)C2CCCCC2)cc1.OB(O)B(O)O â†’ OB(O)c1ccc2[nH]ccc2c1\n",
      "   ğŸ“ˆ Predicted: 73.39% Â± 1.29%\n",
      "   ğŸ§ª Ground truth: 46.13%\n",
      "   â— Error: +27.26%\n",
      "   ğŸ¯ Acquisition: 42.6040\n",
      "   ğŸ’¡ Current best: 46.13%\n",
      "------------------------------------------------------------\n",
      "ğŸ² Random sampling: ('Brc1ccc2c(c1)OCO2', 'c1ccc(-c2ccccc2P(C2CCCCC2)C2CCCCC2)cc1.OB(O)B(O)O')\n",
      "ğŸ” Trial 3: Brc1ccc2c(c1)OCO2 + c1ccc(-c2ccccc2P(C2CCCCC2)C2CCCCC2)cc1.OB(O)B(O)O â†’ OB(O)c1ccc2c(c1)OCO2\n",
      "   ğŸ“ˆ Predicted: 72.39% Â± 1.88%\n",
      "   ğŸ§ª Ground truth: 70.74%\n",
      "   â— Error: +1.65%\n",
      "   ğŸ¯ Acquisition: 26.2538\n",
      "   ğŸ’¡ Current best: 70.74%\n",
      "------------------------------------------------------------\n",
      "ç²å¾—é–¢æ•°å€¤ã‚’è¨ˆç®—ä¸­...\n",
      "ğŸ¯ Exploitation: ('Cc1nc2cc(OS(=O)(=O)N(C)C)ccc2s1', 'c1ccc(-n2cccc2P(C2CCCCC2)C2CCCCC2)cc1.OB(O)B(O)O') (EI: 8.3218)\n",
      "ğŸ” Trial 4: Cc1nc2cc(OS(=O)(=O)N(C)C)ccc2s1 + c1ccc(-n2cccc2P(C2CCCCC2)C2CCCCC2)cc1.OB(O)B(O)O â†’ Cc1nc2cc(B(O)O)ccc2s1\n",
      "   ğŸ“ˆ Predicted: 79.10% Â± 0.86%\n",
      "   ğŸ§ª Ground truth: 0.10%\n",
      "   â— Error: +79.00%\n",
      "   ğŸ¯ Acquisition: 8.3531\n",
      "   ğŸ’¡ Current best: 70.74%\n",
      "------------------------------------------------------------\n",
      "ç²å¾—é–¢æ•°å€¤ã‚’è¨ˆç®—ä¸­...\n"
     ]
    }
   ],
   "source": [
    "# ãƒ™ã‚¤ã‚ºæœ€é©åŒ–ã®å®Ÿè¡Œ\n",
    "best_result = optimizer.optimize(n_trials=30)\n",
    "\n",
    "# æœ€é©åŒ–ã®æ¦‚è¦çµ±è¨ˆã‚’è¡¨ç¤º\n",
    "summary = optimizer.get_optimization_summary()\n",
    "print(f\"\\n=== æœ€é©åŒ–æ¦‚è¦ ===\")\n",
    "print(f\"ç·è©¦è¡Œæ•°: {summary.get('total_trials', 0)}\")\n",
    "print(f\"æœ€é«˜åç‡: {summary.get('max_yield', 0):.2f}%\")\n",
    "print(f\"å¹³å‡åç‡: {summary.get('mean_yield', 0):.2f}%\")\n",
    "print(f\"åç‡æ¨™æº–åå·®: {summary.get('std_yield', 0):.2f}%\")\n",
    "if summary.get('mae_error'):\n",
    "    print(f\"äºˆæ¸¬èª¤å·® (MAE): {summary['mae_error']:.2f}%\")\n",
    "    print(f\"äºˆæ¸¬èª¤å·® (RMSE): {summary['rmse_error']:.2f}%\")\n",
    "print(f\"æ¢ç´¢ç¯„å›²: {summary.get('coverage', 0):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4247de",
   "metadata": {},
   "source": [
    "## å¯è¦–åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rp1kyuwkxx",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_optimization_results(experiment_history, out_dir=None, show=True, dpi=180):\n",
    "    \"\"\"\n",
    "    æœ€é©åŒ–çµæœã®å¯è¦–åŒ–ï¼ˆgreedy_optuna.ipynbã®visualize_logsé–¢æ•°ã‚’å‚è€ƒï¼‰\n",
    "    \n",
    "    Args:\n",
    "        experiment_history: å®Ÿé¨“å±¥æ­´ã®ãƒªã‚¹ãƒˆ\n",
    "        out_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n",
    "        show: ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã™ã‚‹ã‹ã©ã†ã‹\n",
    "        dpi: è§£åƒåº¦\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    if not experiment_history:\n",
    "        print(\"å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\")\n",
    "        return\n",
    "    \n",
    "    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æº–å‚™\n",
    "    if out_dir:\n",
    "        save_dir = os.path.join(out_dir, \"visualization\")\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "    else:\n",
    "        save_dir = None\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™\n",
    "    trials = [exp['trial'] for exp in experiment_history]\n",
    "    actual_yields = [exp['actual_yield'] for exp in experiment_history]\n",
    "    predicted_means = [exp['predicted_mean'] for exp in experiment_history]\n",
    "    predicted_stds = [np.sqrt(exp['predicted_variance']) for exp in experiment_history]\n",
    "    errors = [exp['error_pct'] for exp in experiment_history if exp['error_pct'] is not None]\n",
    "    \n",
    "    # ç´¯ç©æœ€å¤§å€¤ã‚’è¨ˆç®—\n",
    "    cumulative_max = np.maximum.accumulate(actual_yields)\n",
    "    \n",
    "    # å…¨ä½“æŒ‡æ¨™ã®è¨ˆç®—\n",
    "    if len(actual_yields) > 0 and len(errors) > 0:\n",
    "        mae_pct = np.mean(np.abs(errors))\n",
    "        rmse_pct = np.sqrt(np.mean(np.array(errors)**2))\n",
    "        bias_pct = np.mean(errors)\n",
    "        \n",
    "        print(f\"=== å…¨ä½“æŒ‡æ¨™ ===\")\n",
    "        print(f\"è©¦è¡Œæ•°: {len(experiment_history)}\")\n",
    "        print(f\"MAE: {mae_pct:.2f}%\")\n",
    "        print(f\"RMSE: {rmse_pct:.2f}%\")\n",
    "        print(f\"Bias: {bias_pct:+.2f}%\")\n",
    "        print(f\"æœ€é«˜åç‡: {max(actual_yields):.2f}%\")\n",
    "    \n",
    "    # å›³ã®ä½œæˆ\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # 1. ãƒ‘ãƒªãƒ†ã‚£ãƒ—ãƒ­ãƒƒãƒˆï¼ˆäºˆæ¸¬ vs å®Ÿæ¸¬ï¼‰\n",
    "    ax = axes[0, 0]\n",
    "    ax.errorbar(predicted_means, actual_yields, xerr=predicted_stds, \n",
    "               fmt='o', alpha=0.6, capsize=3)\n",
    "    ax.plot([0, 100], [0, 100], 'r--', label='Perfect Prediction')\n",
    "    ax.set_xlabel('Predicted Yield (%)')\n",
    "    ax.set_ylabel('Actual Yield (%)')\n",
    "    ax.set_title('Parity: Prediction vs Truth')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. æœ€é©åŒ–ã®é€²è¡Œ\n",
    "    ax = axes[0, 1]\n",
    "    ax.plot(trials, actual_yields, 'o-', alpha=0.6, label='Actual Yield', markersize=4)\n",
    "    ax.plot(trials, cumulative_max, 'r-', linewidth=2, label='Best So Far')\n",
    "    ax.set_xlabel('Trial')\n",
    "    ax.set_ylabel('Yield (%)')\n",
    "    ax.set_title('Optimization Progress')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. ä¸ç¢ºå®Ÿæ€§ vs å®Ÿæ¸¬åç‡\n",
    "    ax = axes[0, 2]\n",
    "    ax.scatter(predicted_stds, actual_yields, alpha=0.6)\n",
    "    ax.set_xlabel('Prediction Uncertainty (Std)')\n",
    "    ax.set_ylabel('Actual Yield (%)')\n",
    "    ax.set_title('Uncertainty vs Actual Yield')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. èª¤å·®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ \n",
    "    ax = axes[1, 0]\n",
    "    if errors:\n",
    "        ax.hist(errors, bins=20, alpha=0.7, edgecolor='black')\n",
    "        ax.axvline(0, color='red', linestyle='--', label='Perfect Prediction')\n",
    "        ax.set_xlabel('Prediction Error (pred - true) [%]')\n",
    "        ax.set_ylabel('Count')\n",
    "        ax.set_title('Error Histogram')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. äºˆæ¸¬åç‡ã®åˆ†å¸ƒ\n",
    "    ax = axes[1, 1]\n",
    "    ax.hist(predicted_means, bins=20, alpha=0.5, label='Predicted', edgecolor='black')\n",
    "    ax.hist(actual_yields, bins=20, alpha=0.5, label='Actual', edgecolor='black')\n",
    "    ax.set_xlabel('Yield (%)')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('Yield Distribution')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. åç‡ vs è©¦è¡Œç•ªå·ï¼ˆæ•£å¸ƒå›³ï¼‰\n",
    "    ax = axes[1, 2]\n",
    "    ax.scatter(trials, predicted_means, alpha=0.5, label='Predicted', s=20)\n",
    "    ax.scatter(trials, actual_yields, alpha=0.5, label='Actual', s=20)\n",
    "    ax.set_xlabel('Trial')\n",
    "    ax.set_ylabel('Yield (%)')\n",
    "    ax.set_title('Yields over Trials')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # ä¿å­˜\n",
    "    if save_dir:\n",
    "        fig.savefig(os.path.join(save_dir, \"optimization_results.png\"), \n",
    "                   dpi=dpi, bbox_inches=\"tight\")\n",
    "        print(f\"å›³ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {save_dir}/optimization_results.png\")\n",
    "    \n",
    "    if show:\n",
    "        plt.show()\n",
    "    \n",
    "    plt.close(fig)\n",
    "    \n",
    "    return {\n",
    "        'mae_pct': mae_pct if errors else None,\n",
    "        'rmse_pct': rmse_pct if errors else None,\n",
    "        'bias_pct': bias_pct if errors else None,\n",
    "        'max_yield': max(actual_yields) if actual_yields else None,\n",
    "        'save_dir': save_dir\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbb64e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# çµæœã®å¯è¦–åŒ–ï¼ˆæ–°ã—ã„ãƒ—ãƒ­ãƒƒãƒˆé–¢æ•°ã‚’ä½¿ç”¨ï¼‰\n",
    "results = visualize_optimization_results(optimizer.experiment_history, show=True)\n",
    "\n",
    "# ä¸Šä½5ã¤ã®å®Ÿé¨“çµæœã‚’è¡¨ç¤º\n",
    "print(\"\\n=== ä¸Šä½5ã¤ã®å®Ÿé¨“çµæœ ===\")\n",
    "best_experiments = optimizer.get_best_experiments(top_k=5)\n",
    "for i, exp in enumerate(best_experiments, 1):\n",
    "    print(f\"\\n{i}ä½: è©¦è¡Œ{exp['trial'] + 1}\")\n",
    "    print(f\"  Reactant: {exp['reactant']}\")\n",
    "    print(f\"  Reagent: {exp['reagent']}\")\n",
    "    print(f\"  Product: {exp['product']}\")\n",
    "    print(f\"  å®Ÿéš›ã®åç‡: {exp['actual_yield']:.2f}%\")\n",
    "    print(f\"  äºˆæ¸¬åç‡: {exp['predicted_mean']:.2f}% Â± {np.sqrt(exp['predicted_variance']):.2f}%\")\n",
    "    if exp['error_pct'] is not None:\n",
    "        print(f\"  èª¤å·®: {exp['error_pct']:+.2f}%\")\n",
    "    print(f\"  ç²å¾—é–¢æ•°å€¤: {exp['acquisition_value']:.4f}\")\n",
    "\n",
    "# reactant-reagentçµ„ã¿åˆã‚ã›ã®çµ±è¨ˆæƒ…å ±\n",
    "print(\"\\n=== Reactant-Reagentçµ„ã¿åˆã‚ã›çµ±è¨ˆ ===\")\n",
    "combo_stats = optimizer.get_combination_statistics()\n",
    "print(f\"æ¢ç´¢ã•ã‚ŒãŸçµ„ã¿åˆã‚ã›æ•°: {len(combo_stats)}\")\n",
    "\n",
    "# æœ€ã‚‚å¤šãé¸ã°ã‚ŒãŸçµ„ã¿åˆã‚ã›ä¸Šä½3ã¤\n",
    "combo_counts = {combo: len(data) for combo, data in combo_stats.items()}\n",
    "top_combos = sorted(combo_counts.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "\n",
    "print(\"\\næœ€ã‚‚å¤šãæ¢ç´¢ã•ã‚ŒãŸçµ„ã¿åˆã‚ã›:\")\n",
    "for i, ((reactant, reagent), count) in enumerate(top_combos, 1):\n",
    "    avg_yield = np.mean([d['actual_yield'] for d in combo_stats[(reactant, reagent)]])\n",
    "    print(f\"  {i}. {reactant} + {reagent}: {count}å›, å¹³å‡åç‡: {avg_yield:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
